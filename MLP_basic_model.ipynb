{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88fbe16-5ac3-4841-afd1-4023ebef720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flax in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: einops in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: jax in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.31)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.31)\n",
      "Requirement already satisfied: optax in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: rarfile in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.2)\n",
      "Requirement already satisfied: msgpack in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flax) (1.1.0)\n",
      "Requirement already satisfied: tensorstore in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flax) (0.1.67)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flax) (6.0.1)\n",
      "Requirement already satisfied: orbax-checkpoint in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flax) (0.6.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flax) (4.12.2)\n",
      "Requirement already satisfied: rich>=11.1 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flax) (13.7.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: chex>=0.1.86 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optax) (0.1.87)\n",
      "Requirement already satisfied: etils[epy] in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optax) (1.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from optax) (2.1.0)\n",
      "Requirement already satisfied: toolz>=0.9.0 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chex>=0.1.86->optax) (1.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=11.1->flax) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Requirement already satisfied: humanize in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from orbax-checkpoint->flax) (4.11.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from orbax-checkpoint->flax) (4.25.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[epy]->optax) (6.4.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[epy]->optax) (2024.6.1)\n",
      "Requirement already satisfied: zipp in c:\\users\\samar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[epy]->optax) (3.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install flax einops jax jaxlib optax rarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d5967-5f78-4ee8-8076-1bf8d28e70ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50810655-1a11-4270-bad4-c2704a29131e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0630bc6e-9951-493b-ac51-3b3ea3c0f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b9c054-8076-42cc-934c-c6104a8637e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpBlock(nn.Module):\n",
    "    mlp_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        y = nn.Dense(self.mlp_dim)(x)\n",
    "        y = nn.gelu(y)\n",
    "        return nn.Dense(x.shape[-1])(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8e2649-2705-4bf7-8eba-6e2b82cb3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(nn.Module):\n",
    "    tokens_mlp_dim: int\n",
    "    channels_mlp_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        y = nn.LayerNorm()(x)\n",
    "        y = jnp.swapaxes(y, 1, 2)\n",
    "        y = MlpBlock(self.tokens_mlp_dim)(y)\n",
    "        y = jnp.swapaxes(y, 1, 2)\n",
    "        x = x + y\n",
    "        y = nn.LayerNorm()(x)\n",
    "        return x + MlpBlock(self.channels_mlp_dim)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e4419e-3306-4618-82c4-5b9b8d8e93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpMixer(nn.Module):\n",
    "    num_classes: int\n",
    "    num_blocks: int\n",
    "    patch_size: int\n",
    "    hidden_dim: int\n",
    "    tokens_mlp_dim: int\n",
    "    channels_mlp_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        s = self.patch_size\n",
    "        x = nn.Conv(self.hidden_dim, (s, s), strides=(s, s))(x)\n",
    "        x = einops.rearrange(x, 'n h w c -> n (h w) c')\n",
    "        \n",
    "        for _ in range(self.num_blocks):\n",
    "            x = MixerBlock(self.tokens_mlp_dim, self.channels_mlp_dim)(x)\n",
    "        \n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = jnp.mean(x, axis=1)\n",
    "        return nn.Dense(self.num_classes)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9fc35c0-5617-4969-9f91-04d83db1c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=32, img_size=(224, 224)):\n",
    "    dataset_path = \"fold1_separated_2_classes\"  \n",
    "\n",
    "    train_dir = os.path.join(dataset_path, \"train\")\n",
    "    test_dir = os.path.join(dataset_path, \"test\")\n",
    "    \n",
    "    if not os.path.exists(train_dir):\n",
    "        raise FileNotFoundError(f\"Train directory not found: {train_dir}\")\n",
    "    if not os.path.exists(test_dir):\n",
    "        raise FileNotFoundError(f\"Test directory not found: {test_dir}\")\n",
    "\n",
    "    train_ds = image_dataset_from_directory(\n",
    "        train_dir,  \n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    test_ds = image_dataset_from_directory(\n",
    "        test_dir,  \n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab9200a-56e5-435f-8a18-46bc2bcbccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    batch_stats: dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27822a3f-cbb1-4d1c-93fb-3862687761a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, batch['image'])\n",
    "        loss = optax.softmax_cross_entropy(logits, jax.nn.one_hot(batch['label'], num_classes=2)).mean()\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)  # Unpack loss here\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    accuracy = (jnp.argmax(logits, -1) == batch['label']).mean()\n",
    "    return state, loss, accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef7434f-9759-46ff-a661-7e6afda54169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(state, train_ds, test_ds, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_ds:\n",
    "            batch = {'image': jnp.array(batch[0] / 255.0), 'label': jnp.array(batch[1])}\n",
    "            state, loss, accuracy = train_step(state, batch)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02411bae-6d12-432c-a7ed-4a4d1afddaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5005 files belonging to 4 classes.\n",
      "Found 2904 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = MlpMixer(num_classes=num_classes, num_blocks=8, patch_size=4, hidden_dim=128, tokens_mlp_dim=256, channels_mlp_dim=512)\n",
    "\n",
    "train_ds, test_ds = load_data()\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dummy_input = jnp.ones((1, 224, 224, 1))  \n",
    "params = model.init(rng, dummy_input)['params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdca424-de7a-40c0-bb5f-3237aa9f2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = TrainState.create(\n",
    "#     apply_fn=model.apply,\n",
    "#     params=params,\n",
    "#     tx=optax.adam(1e-3),\n",
    "# )\n",
    "\n",
    "# train_model(state, train_ds, test_ds, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd61ee46-134d-4abf-9ae0-b89b938181be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import einops\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MlpBlock(nn.Module):\n",
    "    mlp_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        y = nn.Dense(self.mlp_dim)(x)\n",
    "        y = nn.gelu(y)\n",
    "        return nn.Dense(x.shape[-1])(y)\n",
    "\n",
    "class MixerBlock(nn.Module):\n",
    "    tokens_mlp_dim: int\n",
    "    channels_mlp_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        y = nn.LayerNorm()(x)\n",
    "        y = jnp.swapaxes(y, 1, 2)\n",
    "        y = MlpBlock(self.tokens_mlp_dim)(y)\n",
    "        y = jnp.swapaxes(y, 1, 2)\n",
    "        x = x + y\n",
    "        y = nn.LayerNorm()(x)\n",
    "        return x + MlpBlock(self.channels_mlp_dim)(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbd4e64-0be6-44f9-b965-77ae1e1c281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpMixer(nn.Module):\n",
    "    num_classes: int\n",
    "    num_blocks: int\n",
    "    patch_size: int\n",
    "    hidden_dim: int\n",
    "    tokens_mlp_dim: int\n",
    "    channels_mlp_dim: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        s = self.patch_size\n",
    "        x = nn.Conv(self.hidden_dim, (s, s), strides=(s, s))(x)\n",
    "        x = einops.rearrange(x, 'n h w c -> n (h w) c')\n",
    "        \n",
    "        for _ in range(self.num_blocks):\n",
    "            x = MixerBlock(self.tokens_mlp_dim, self.channels_mlp_dim)(x)\n",
    "        \n",
    "        x = nn.LayerNorm()(x)\n",
    "        x = jnp.mean(x, axis=1)\n",
    "        return nn.Dense(self.num_classes)(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc7e17f6-3496-4233-bcf1-46651b64ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=32, img_size=(224, 224)):\n",
    "    dataset_path = \"breast-ultrasound-dataset\"\n",
    "\n",
    "    train_dir = os.path.join(dataset_path, \"train_dir\")\n",
    "    valid_dir = os.path.join(dataset_path, \"valid_dir\")\n",
    "    test_dir = os.path.join(dataset_path, \"test_dir\")\n",
    "    \n",
    "    if not all(os.path.exists(d) for d in [train_dir, valid_dir, test_dir]):\n",
    "        raise FileNotFoundError(\"One or more dataset directories not found.\")\n",
    "    \n",
    "    train_ds = image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    valid_ds = image_dataset_from_directory(\n",
    "        valid_dir,\n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    test_ds = image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        label_mode='int',\n",
    "        image_size=img_size,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return train_ds, valid_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "075d9ebc-309f-4c49-a15f-40d9dc0fcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, batch['image'])\n",
    "        loss = optax.softmax_cross_entropy(logits, jax.nn.one_hot(batch['label'], num_classes=3)).mean()\n",
    "        return loss, logits\n",
    "\n",
    "    (loss, logits), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    \n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    accuracy = (jnp.argmax(logits, -1) == batch['label']).mean()\n",
    "    \n",
    "    return state, loss, accuracy\n",
    "\n",
    "\n",
    "def train_model(state, train_ds, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_ds:\n",
    "            batch = {'image': jnp.array(batch[0] / 255.0), 'label': jnp.array(batch[1])}\n",
    "            \n",
    "            state, loss, accuracy = train_step(state, batch)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f313233-586f-490e-bb76-9bb8b0b841f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 606 files belonging to 3 classes.\n",
      "Found 187 files belonging to 3 classes.\n",
      "Found 150 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    pass \n",
    "\n",
    "num_classes = 3\n",
    "model = MlpMixer(num_classes=num_classes, num_blocks=8, patch_size=4, hidden_dim=128, tokens_mlp_dim=256, channels_mlp_dim=512)\n",
    "\n",
    "train_ds, valid_ds, test_ds = load_data()\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dummy_input = jnp.ones((1, 224, 224, 1))  \n",
    "params = model.init(rng, dummy_input)['params']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b084b-252b-44ff-a63c-c551faa8749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9502, Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optax.adam(1e-3),\n",
    ")\n",
    "\n",
    "train_model(state, train_ds, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5c4ecd-685c-4af6-bd5e-80659a06246a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
